{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "028dcd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1500it [00:00, 93762.38it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def find_lcsubstr(str_a, str_b):\n",
    "#  longest common subsequence of str_a and str_b, with O(n) space complexity\n",
    "    if len(str_a) == 0 or len(str_b) == 0:\n",
    "        return 0\n",
    "    dp = [0 for _ in range(len(str_b) + 1)]\n",
    "    for i in range(1, len(str_a) + 1):\n",
    "        left_up = 0\n",
    "        dp[0] = 0\n",
    "        for j in range(1, len(str_b) + 1):\n",
    "            left = dp[j-1]\n",
    "            up = dp[j]\n",
    "            if str_a[i-1] == str_b[j-1]:\n",
    "                dp[j] = left_up + 1\n",
    "            else:\n",
    "                dp[j] = max([left, up])\n",
    "            left_up = up\n",
    "    return dp[len(str_b)]/min(len(str_b),len(str_a))\n",
    "\n",
    "def data_loading(path):\n",
    "    all_keys = ['question_id','question','qas_id','doc_tokens','answer_text','start_position','end_position','is_impossible']\n",
    "    all_values = [[] for i in range(len(all_keys))]\n",
    "    final_dic = dict(zip(all_keys,all_values))\n",
    "    with open(path,encoding='utf-8') as json_file:\n",
    "        for line in tqdm(json_file):\n",
    "            data = json.loads(line)\n",
    "            current_keys = data.keys()\n",
    "            for key in current_keys:\n",
    "                final_dic[key].append(data[key])\n",
    "    final_pd = pd.DataFrame(final_dic)\n",
    "    final_pd.start_position = final_pd.start_position.replace({-1:0})\n",
    "    final_pd.end_position = final_pd.end_position.replace({-1:0})\n",
    "    return final_pd\n",
    "\n",
    "test_df_location = 'cleaned_data_test.json'\n",
    "evaluate_file = '1130_roberta_3.0data.json'\n",
    "\n",
    "test_df = data_loading(test_df_location)\n",
    "all_qas_id = list(test_df['qas_id'])\n",
    "all_question = list(test_df['question'])\n",
    "all_doc_tokens = list(test_df['doc_tokens'])\n",
    "answer_all = list(test_df['answer_text'])\n",
    "final_qas_map = dict(zip(all_qas_id,answer_all))\n",
    "final_que_map = dict(zip(all_qas_id,all_question))\n",
    "final_doc_map = dict(zip(all_qas_id,all_doc_tokens))\n",
    "shot_ans = ['是什么','在哪里','哪位','哪国','国家','国籍','哪个朝代','本名','原名','哪个','哪一个','哪','最','几次','是谁','学名','第一个','第一','最大','最小','最长','最深','最高','最多','第一','作者','叫什么名字','名字','叫什么']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aafc983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "def check_relevance(question, answer, do_filter=False, threshould = 0.2):  # do_filter表示是否返回合格答案 True则返回 False只返回判断\n",
    "    check_list = ['建议','当地','需要','确定','咨询','询问','客服','相关','部门','有关部门','私信','同求','您好','办理','手续','及时']\n",
    "    right_list = ['这种情况','情况','病史','描述','叙述','根治','缓解','改善','症状','表现','食用','口服','服用','导致','表现','形容',\n",
    "    '危险','根据你的描述','引起的','根据','正常','可能是','你说的','导致的','造成的','检查一下','试试','尝试','进行治疗','检查','治疗',\n",
    "    '药物治疗','治疗中','相关治疗','治疗方式','治疗方案','治疗效果','常规治疗','其他治疗','治疗后','手术治疗','治疗方法','综合治疗',\n",
    "    '系统治疗','治疗手段','治疗方面','中医治疗','治疗措施','治疗过程中','疾病的治疗','对症治疗','持续治疗','临床治疗','其它治疗',\n",
    "    '西医治疗','保守治疗','医治','长期治疗','治疗效果不佳','一般治疗','治疗法']\n",
    "    flag = 0 # flag = 1 代表这个数据中存在合格答案 （长度大于20且无关键词）\n",
    "    mark = 0\n",
    "    valid_answer = ''\n",
    "    sentence = answer\n",
    "    current_sentence = [i for i in jieba.cut(sentence, cut_all=False)]\n",
    "    current_question = [i for i in jieba.cut(question, cut_all=False)]\n",
    "#         current_sentence = [i.term for i in wordseg.segment(sentence).basic_words]\n",
    "#         current_question = [i.term for i in wordseg.segment(question).basic_words]\n",
    "    for item in right_list:\n",
    "        if item in sentence:\n",
    "            flag = 1\n",
    "            valid_answer = sentence if do_filter else 0\n",
    "            break\n",
    "    if flag == 1 and do_filter:\n",
    "        return valid_answer, flag\n",
    "    elif flag == 1 and not do_filter:\n",
    "        return flag\n",
    "    \n",
    "    else:\n",
    "        if len(current_sentence) <= 20: # 长度小于20的情况\n",
    "            for item in check_list:\n",
    "                if item in sentence:\n",
    "                    mark = 1\n",
    "                    break\n",
    "            if mark == 1 and do_filter: # 包含关键词不考虑\n",
    "                return valid_answer, flag\n",
    "            elif mark == 1 and not do_filter:\n",
    "                return flag\n",
    "            else: # 小于20单不包含关键词 则判断问题答案重叠率\n",
    "                final_q = set(current_question)\n",
    "                candidate_all = final_q.intersection(set(current_sentence))\n",
    "                if len(candidate_all)/len(final_q) >= threshould:\n",
    "                    flag = 1\n",
    "                    valid_answer = sentence\n",
    "\n",
    "        elif len(current_sentence) > 20:  # 长度大于20的情况\n",
    "            final_q = set(current_question)\n",
    "            candidate_all = final_q.intersection(set(current_sentence))\n",
    "            if len(candidate_all)/len(final_q) >=threshould: #重叠率判断\n",
    "                flag = 1\n",
    "                valid_answer = sentence\n",
    "                \n",
    "    if do_filter:\n",
    "        return valid_answer, flag\n",
    "    else:\n",
    "        return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4843f95a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_prediction_RoBERTA(path, final_qas_map,final_que_map, final_doc_map):\n",
    "    final_content = []\n",
    "    final_question = []\n",
    "    final_answer = []\n",
    "    final_prediction = []\n",
    "    final_flag_prediction = []\n",
    "    final_flag_answer = []\n",
    "    \n",
    "    prediction_result_100 = []\n",
    "    prediction_result_60 = []\n",
    "    prediction_not_null_60 = []\n",
    "    prediction_not_null_100 = []\n",
    "    count = 0\n",
    "    with open(path, \"r\",encoding='utf-8') as f:\n",
    "        all_data = f.readlines()\n",
    "        for line in tqdm(all_data):\n",
    "            current_object = json.loads(line)\n",
    "            qas_id = current_object['question_ID']\n",
    "            actual_answer = ''.join(current_object['answer'].split())\n",
    "            actual_answer_final = final_qas_map[qas_id]\n",
    "            prediction = ''.join(current_object['prediction'].split())\n",
    "            \n",
    "            if actual_answer_final!='':\n",
    "                final_content.append('Paragraph:'+ final_doc_map[qas_id])\n",
    "                final_question.append('Question' + final_que_map[qas_id])\n",
    "                final_answer.append('Answer:' +actual_answer_final)\n",
    "                final_prediction.append('Prediction:' + prediction)\n",
    "                final_flag_prediction.append('Prediction_relevancy:'+str(check_relevance(final_que_map[qas_id], prediction)))      \n",
    "                final_flag_answer.append('Answer_relevancy:'+str(check_relevance(final_que_map[qas_id], actual_answer_final)))   \n",
    "            \n",
    "            if actual_answer == prediction and actual_answer == '':\n",
    "                prediction_result_100.append(1)\n",
    "                prediction_result_60.append(1)\n",
    "            else:\n",
    "                overlap_rate = find_lcsubstr(actual_answer, prediction)\n",
    "                if overlap_rate == 1: # 考虑包含情况\n",
    "                    prediction_result_100.append(1)\n",
    "                else:\n",
    "                    prediction_result_100.append(0)\n",
    "                if overlap_rate >=0.6: #考虑包含情况\n",
    "                    prediction_result_60.append(1)\n",
    "                else:\n",
    "                    prediction_result_60.append(0)\n",
    "#             (prediction in answer and len(prediction)/len(answer)>=0.5)\n",
    "            if actual_answer_final!='':\n",
    "                overlap_rate = find_lcsubstr(actual_answer, prediction)\n",
    "                if overlap_rate == 1:\n",
    "                    prediction_not_null_100.append(1)\n",
    "                else:\n",
    "                    prediction_not_null_100.append(0)\n",
    "                if overlap_rate >= 0.6:\n",
    "                    prediction_not_null_60.append(1)\n",
    "                else:\n",
    "                    prediction_not_null_60.append(0)\n",
    "                    \n",
    "            if actual_answer_final!='':\n",
    "                    count +=1\n",
    "        \n",
    "        \n",
    "        print('RoBERTa all prediction, total length:{}'.format(len(prediction_result_100)))\n",
    "        print('100% 相同情况下 准确率：', prediction_result_100.count(1)/len(prediction_result_100))\n",
    "        print('60% 相同情况下 准确率：', prediction_result_60.count(1)/len(prediction_result_60))\n",
    "        print('非空总数：{}'.format(count))\n",
    "        print('100% 相同情况下 答案非空 准确率：', prediction_not_null_100.count(1)/len(prediction_not_null_100))\n",
    "        print('60% 相同情况下 答案非空 准确率：', prediction_not_null_60.count(1)/len(prediction_not_null_60))\n",
    "        \n",
    "    final_dic = list(zip(final_content,final_question,final_answer,final_prediction,final_flag_answer, final_flag_prediction))\n",
    "    \n",
    "    required_dic = list(zip(final_question,final_answer,final_flag_answer, final_prediction, final_flag_prediction))\n",
    "    return final_dic,required_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0a5baf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:00<00:00, 1838.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa all prediction, total length:1500\n",
      "100% 相同情况下 准确率： 0.9533333333333334\n",
      "60% 相同情况下 准确率： 0.9586666666666667\n",
      "非空总数：1297\n",
      "100% 相同情况下 答案非空 准确率： 0.9491133384734002\n",
      "60% 相同情况下 答案非空 准确率： 0.9552814186584425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_dic_ROBERTA,required_dic_ROBERTA  = load_prediction_RoBERTA(evaluate_file, final_qas_map,final_que_map, final_doc_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a2089a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('sample_show.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in required_dic_ROBERTA:\n",
    "        f.write('\\t'.join(i))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a3c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
